\section{Limits, Part I (The Blessed Path)}

\subsection{Precalculus}

I'll first do a hand-wavy definition of limits, and then use it to
explain the mechanics of computing limits of functions in practice.
Basically, pre-calculus stuff. After that I'll do a proper definition
and use it to prove the theorems that make the mechanics work.

\vs

\textbf{A hand-wavy definition:} a limit of $f(x)$ at $a$ is the value
$f(x)$ approaches close to (but not necessarily at) $a$.

\vs

\textbf{A slightly less hand-wavy definition:} let $f:\R\to\R$, let
$a\in\R$ be some number on the x-axis, and let $l\in\R$ be some number on
the y-axis. Then as $x$ gets closer to $a$, $f(x)$ gets closer to $l$.

\vs

The notation for this whole thing is

\[\lim_{x\to a} f(x)=l\]

So for example $\lim_{x\to5}x^2=25$ because the closer $x$ gets to
$5$, the closer $x^2$ gets to $25$ (we'll prove all this properly
soon). Now suppose you have some fancy pants function like this one:
\begin{equation}
\label{eq:1}
\lim_{x\to 0}\frac{1-\sqrt{x}}{1-x}
\end{equation}

If you plot it, it's easy to see that as $x$ approaches $0$, the whole
shebang approaches $1$. But how do you algebraically evaluate the
limit of this thing? Can you just plug $0$ into the equation? It seems
to work, but once we formally define limits, we'll have to prove
somehow that plugging $a=0$ into $x$ gives us the correct result.

\subsubsection*{Limits evaluation mechanics}

It turns out that it does in fact work because of a few theorems that
make practical evaluation of many limits easy. I'll first state these
theorems as facts, and then go back and properly prove them once I
introduce the formal definition of limits.

\begin{enumerate}
\item \textbf{Constants}. $\lim_{x\to a}c=c$, where $c\in\R$. In other
  words if the function is a constant, e.g. $f(x)=5$, then
  $\lim_{x\to a}f(x)=5$ for any $a$.
\item \textbf{Identity}. $\lim_{x\to a}x=a$. In other words if the
  function is an identity function $f(x)=x$, then
  $\lim_{x\to 6}f(x)=6$. Meaning we simply plug $a$ into $x$.
\item \textbf{Addition}\footnote{Spivak's book uses a slightly more
    verbose definition that assumes the limits of $f$ and $g$ exist
    near $a$, see p. 103}.
  $\lim_{x\to a}(f+g)(x)=\lim_{x\to a}f(x)+\lim_{x\to a}g(x)$. For example
  $\lim_{x\to a}(x+2)=\lim_{x\to a}x+\lim_{x\to a}2=a+2$.
\item \textbf{Multiplication}.
  $\lim_{x\to a}(f\cdot g)(x)=\lim_{x\to a}f(x)\cdot \lim_{x\to a}g(x)$. For example
  $\lim_{x\to a}2x=\lim_{x\to a}2\cdot \lim_{x\to a}x=2a$.
\item \textbf{Reciprocal}.
  $\lim_{x\to a}\left(\frac{1}{f}\right)(x)=\frac{1}{\lim_{x\to a}f(x)}$
  when the denominator isn't zero. For example
  $\lim_{x\to a}\frac{1}{x}=\frac{1}{\lim_{x\to a}x}=\frac{1}{a}$ for
  $a\neq0$.
\end{enumerate}

To come back to \ref{eq:1}, these theorems tells us that

\[\lim_{x\to 0}\frac{1-\sqrt{x}}{1-x}=\frac{\lim_{x\to 0}1-(\lim_{x\to 0}x)^{\frac{1}{2}}}{\lim_{x\to 0}1-\lim_{x\to 0}x}=\frac{1-0^{\frac{1}{2}}}{1-0}=1\]

\subsubsection*{Holes}

What happens if we try to take a limit as $x\to 1$ rather than $x\to 0$?

\[\lim_{x\to 1}\frac{1-\sqrt{x}}{1-x}\]

We can't use the same trick and plug in $1$ because we get a
nonsensical result $0/0$ as the function isn't defined at $0$. If we
plot it, we clearly see the limit approaches $1/2$ at $0$, but how do
we prove this algebraically? The answer is to do some trickery to find
a way to cancel out the inconvenient term (in this case $1-\sqrt{x}$)

\[\lim_{x\to 1}\frac{1-\sqrt{x}}{1-x}=\lim_{x\to 1}\frac{1-\sqrt{x}}{(1-\sqrt{x})(1+\sqrt{x})}=\lim_{x\to 1}\frac{1}{1+\sqrt{x}}=\frac{1}{2}\]

\vs

Why is it ok here to divide by $1-\sqrt{x}$? Good question! Recall
that the limit is defined \textit{close to} $a$ (or \textit{around}
$a$, or as $x$ \textit{approaches} $a$), but not \textbf{at} $a$. In
other words $f(a)$ need not even be defined (as is the case here).
This means that as we consider $1-\sqrt{x}$ at different values of $x$
as it approaches $a$, the limit never requires us to evaluate the
function at $x=a$. So we never have to consider $1-\sqrt{x}$ as $x=1$,
$1-\sqrt{x}$ never takes on the value of $0$, and it is safe to divide
it out.

\subsection{Formal limits definition}

Now we establish a rigorous definition of limits that formalizes the
hand-wavy version above.

\paragraph{Definition:} $\lim_{x\to a}f(x)=L$ when for any
$\epsilon\in\R$ there exists $\delta\in\R$ such that for all $x$,
$0<|x-a|<\delta$ implies $|f(x)-L|<\epsilon$. (Also $\epsilon>0, \delta>0$.)

\vs

Here is what this says. Suppose $\lim_{x\to a}f(x)=L$. You pick any
interval on the y-axis around $L$. Make it as small (or as large) as
you want. I'll produce an interval on the x-axis around $a$. You can
take any number from my interval, plug it into $f$, and the output
will stay within the bounds you specified.

\vs

So $\epsilon$ specifies the distance away from $L$ along the y-axis, and
$\delta$ specifies the distance away from $a$ along the x-axis. Take any
$x$ within $\delta$ of $a$, plug it into $f$, and the result is guaranteed
to be within $\epsilon$ of $L$. $\lim_{x\to a}f(x)=L$ just means there exists
such $\delta$ for any $\epsilon$.

\vs

This is quite simple, but the mechanics of the limit definition tend
to confuse people. I think it's because absolute value inequalities
are unfamiliar. Wtf is $0<|x-a|<\delta$ and $|f(x)-L|<\epsilon$?! Let's tease it
apart\footnote{The best answer is to go to Khan academy and do a bunch
  of absolute value inequalities until they become second nature.}

\vs

Here is the intuitive reading. $0<|x-a|<\delta$ means the difference
between $x$ and $a$ is between $0$ and $\delta$. And
$|f(x)-L|<\epsilon$ means the difference between $f(x)$ and $L$ is less than
$\epsilon$. This is actually all this means, but still, let's look at the
inequalities more closely.

\vs

First, consider $0<|x-a|<\delta$. There are two inequalities here. The left
side, $0<|x-a|$ is equivalent to $|x-a|>0$. But $|x-a|$ is an absolute
value, it's \textbf{always} true that $|x-a|\geq 0$. So this part of the
inequality says $x-a\neq 0$, or $x\neq a$. (Remember, we said the limit is
defined \textit{around} $a$ but not \textit{at} $a$). I don't know why
mathematicians say $0<|x-a|$ instead of $x\neq a$, probably because
confusing you brings them pleasure.

\vs

The right side is $|x-a|<\delta$. Intuitively this says that along the
x-axis the difference between $x$ and $a$ should be less than
$\delta$. Put differently, $x$ should be within $\delta$ of $a$. We can rewrite
this as $a-\delta<x<a+\delta$.

\vs

The second equation, $|f(x)-L|<\epsilon$ should now be easy to understand.
Intuitively, along the y-axis $f(x)$ should be within $\epsilon$ of
$L$, or put differently $L-\epsilon<f(x)<L+\epsilon$.

\subsubsection*{Limit uniqueness}

Suppose $\lim_{x\to a}f(x)=L$. It's easy to assume $L$ is the only limit
around $a$, but such a thing needs to be proved. We prove this here.
More formally, suppose $\lim_{x\to a}f(x)=L$ and
$\lim_{x\to a}f(x)=M$. We prove that $L=M$.

\vs

Suppose for contradiction $L\neq M$. Assume without loss of generality
$L>M$. By limit definition, for all $\epsilon>0$ there exists a positive
$\delta\in\R$ such that $0<|x-a|<\delta$ implies

\begin{itemize}
\item $|f(x)-L|<\epsilon\implies L-\epsilon<f(x)$
\item $|f(x)-M|<\epsilon\implies f(x)<M+\epsilon$
\end{itemize}
    
for all $x$. Thus

\begin{align*}
    &L-\epsilon<f(x)<M+\epsilon\\
    &\implies L-\epsilon<M+\epsilon\\
    &\implies L-M<2\epsilon\\
\end{align*}

The above is true for all $\epsilon$. Now let's narrow our attention and
consider a concrete $\epsilon=(L-M)/4$, which we easily find leads to a
contradiction\footnote{note we assumed $L>M$, thus $\epsilon=(L-M)/4>0$}:

\begin{align*}
    &L-M<2\epsilon\\
    &\implies (L-M)/4<\epsilon/2&&\text{dividing both sides by 4}\\
    &\implies \epsilon<\epsilon/2&&\text{recall we set $\epsilon=(L-M)/4$}
\end{align*}

We have a contradiction, and so $L=M$ as desired.

\subsubsection*{Half-Value Neighborhood Lemma} \label{subsubsec:half-value-lemma}

This lemma will come in handy later, so we may as well prove it now.
Suppose $M\neq0$ and $\lim_{x\to a}g(x)=M$. We show that there exists some
$\delta$ such that $0<|x-a|<\delta$ implies $|g(x)|\geq|M|/2$ for all $x$.

\vs

Intuitively, the lemma states the following: when a function $g$
approaches a nonzero limit $M$ near a point, there exists an interval
in which the values of $g$ are closer to $M$ than to zero.

\paragraph{Proof.} The claim that $|g(x)|\geq|M|/2$ is equivalent to
\[g(x)\leq-|M|/2 \text{\ \ \ or\ \ \ }g(x)\geq|M|/2\]

There are two possibilities: either $M>0$ or $M<0$. Let's consider
each possibility separately.

\vs

\textbf{Case 1}. Suppose $M>0$. Then to show $|g(x)|\geq|M|/2$ it is
sufficient to show \textit{either} $g(x)\leq-M/2$ or $g(x)\geq M/2$. We will
show $g(x)\geq M/2$. Fix $\epsilon=M/2$. By limit definition there is some
$\delta$ such that $0<|x-a|<\delta$ implies for all $x$
\begin{align*}
    &|g(x)-M|<M/2\\
    &\implies -M/2<g(x)-M\\
    &\implies M/2<g(x)&&\text{add $M$ to both sides}\\
    &\implies g(x)>M/2&&\text{note $\geq$ is correct but not tight}
\end{align*}

\textbf{Case 2}. Suppose $M<0$. We must show either $g(x)\leq M/2$ or
$g(x)\geq -M/2$. We will show $g(x)\leq M/2$. Fix $\epsilon=-M/2$. Then
\begin{align*}
    &|g(x)-M|<-M/2\\
    &\implies g(x)-M<-M/2\\
    &\implies g(x)<M/2&&\text{add $M$ to both sides;}\\
    & &&\text{note $\leq$ is correct but not tight}
\end{align*}
QED.

\subsection{Theorems that make evaluation work}

Armed with the formal definition, we can use it to rigorously prove
the five theorems useful for evaluating limits (constants, identity,
addition, multiplication, reciprocal). Let's do that now.

\subsubsection*{Constants}
Let $f(x)=c$. We prove that $\lim_{x\to a}f(x)=c$ for all $a$.

\vs

Let $\epsilon>0$ be given. Pick any positive $\delta$. Then for all
$x$ such that $0<|x-a|<\delta$, $|f(x)-c|=|c-c|=0<\epsilon$. QED.

\vs

(Note that we can pick any positive $\delta>0$, e.g.
$1, 10, \frac{1}{10}$.)

\subsubsection*{Identity}

Let $f(x)=x$. We prove that $\lim_{x\to a}f(x)=a$ for all $a$.

\vs

Let $\epsilon>0$ be given. We need to find $\delta>0$ such that for all
$x$ in $0<|x-a|<\delta$, $|f(x)-a|=|x-a|<\epsilon$. I.e. we need to find a
$\delta$ such that $|x-a|<\delta$ implies $|x-a|<\epsilon$. This obviously works for
any $\delta\leq\epsilon$. QED.

\vs

(Note the many options for $\delta$, e.g. $\delta=\epsilon$, $\delta=\frac{\epsilon}{2}$, etc.)

\subsubsection*{Addition}

Let $f,g\in\R\to\R$. We prove that

\[\lim_{x\to a}(f+g)(x)=\lim_{x\to a}f(x)+\lim_{x\to a}g(x)\]

Let $L_f=\lim_{x\to a}f(x)$ and let $L_g=\lim_{x\to a}g(x)$. Let
$\epsilon>0$ be given. We must show there exists $\delta>0$ such that for all
$x$ bounded by $0<|x-a|<\delta$ the following inequality holds:

\begin{equation*}
|(f+g)(x)-(L_f+L_g)|<\epsilon    
\end{equation*}

I.e. we're trying to show $\lim_{x\to a}(f+g)(x)$ equals to $L_f+L_g$,
the sum of the other two limits. Let's convert the left side of this
inequality into a more convenient form:

\begin{align*}
    |(f+g)(x)-(L_f+L_g)|&=|f(x)+g(x)-(L_f+L_g)|\\
    &=|(f(x)-L_f)+(g(x)-L_g)|\\
    &\leq |(f(x)-L_f)|+|(g(x)-L_g)|&&\text{by triangle inequality}
\end{align*}

\vs

By limit definition there exist positive $\delta_f, \delta_g$ such that for all $x$

\begin{itemize}
    \item $0<|x-a|<\delta_f$ implies $|f(x)-L_f|<\epsilon/2$
    \item $0<|x-a|<\delta_g$ implies $|g(x)-L_g|<\epsilon/2$
\end{itemize}

Recall that we can make $\epsilon$ as small as we like. Here we pick deltas
for $\epsilon/2$ because it's convenient to make the equations work, as you
will see in a second. For all $x$ bounded by
$0<|x-a|<\min(\delta_f, \delta_g)$ we have

\[|(f(x)-L_f)|<\epsilon/2 \ \ \ \text{ and }\ \ \  |(g(x)-L_g)|<\epsilon/2\]

Fix $\delta=\min(\delta_f, \delta_g)$. Then for all $x$ bounded by
$0<|x-a|<\delta$ we have

\begin{align*}
    |(f+g)(x)-(L_f+L_g)|&\leq |(f(x)-L_f)|+|(g(x)-L_g)|\\
    &<\epsilon/2+\epsilon/2=\epsilon
\end{align*}

as desired.

\subsubsection*{Multiplication}

Let $f,g\in\R\to\R$. We prove that

\[\lim_{x\to a}(fg)(x)=\lim_{x\to a}f(x)\cdot\lim_{x\to a}g(x)\]

Let $L_f=\lim_{x\to a}f(x)$ and let $L_g=\lim_{x\to a}g(x)$. Let
$\epsilon>0$ be given. We must show there exists $\delta>0$ such that for all
$x$ bounded by $0<|x-a|<\delta$ the following inequality holds:

\[|(fg)(x)-(L_fL_g)|<\epsilon\]

(i.e. we're trying to show $\lim_{x\to a}(fg)(x)$ equals to $L_fL_g$,
the product of the other two limits.) Let's convert the left side of
this inequality into a more convenient form:

\begin{align*}
    |(fg)(x)-(L_fL_g)|&=|f(x)g(x)-L_fL_g|\\
    &=|f(x)g(x)-L_fg(x)+L_fg(x)-L_fL_g|\\
    &=|g(x)(f(x)-L_f)+L_f(g(x)-L_g)|\\
    &\leq|g(x)(f(x)-L_f)|+|L_f(g(x)-L_g)|&&\text{by triangle inequality}\\
    &=|g(x)||f(x)-L_f|+|L_f||g(x)-L_g|&&\text{in general } |ab|=|a||b|
\end{align*}

We now need to show there exists $\delta$ such that $0<|x-a|<\delta$ implies

\[|g(x)||f(x)-L_f|+|L_f||g(x)-L_g|<\epsilon\]

We will do that by finding $\delta$ such that

\begin{enumerate}
    \item $|g(x)||f(x)-L_f|<\epsilon/2$
    \item $|L_f||g(x)-L_g|<\epsilon/2$
\end{enumerate}

\textbf{First}, we show $|g(x)||f(x)-L_f|<\epsilon/2$.

\vs

By limit definition we can find $\delta_1$ to make $|f(x)-L_f|$ as small as
we like. But how small? To make $|g(x)||f(x)-L_f|<\epsilon/2$ we must find a
delta such that $|f(x)-L_f|<\epsilon/2g(x)$. But to do that we need to get a
bound on $g(x)$. Fortunately we know there exists $\delta_2$ such that
$|g(x)-L_g|<1$ (we pick $1$ because we must pick some bound, and $1$
is as good as any). Thus $|g(x)|<|L_g|+1$. And so, we can pick
$\delta_1$ such that $|f(x)-L_f|<\epsilon/2(|L_g|+1)$.

\vs

\textbf{Second}, we show $|L_f||g(x)-L_g|<\epsilon/2$.

\vs

That is easy. By limit definition there exists a $\delta_3$ such that
$0<|x-a|<\delta_3$ implies $|g(x)-L_g|<\epsilon/2|L_f|$ for all $x$. Actually, we
need a $\delta_3$ such that $0<|x-a|<\delta_3$ implies
$|g(x)-L_g|<\frac{\epsilon}{2(|L_f|+1)}$ for all $x$ to avoid divide by zero, and of
course that exists too.

\vs

Fix $\delta=\min(\delta_1, \delta_2, \delta_3)$. Now

\begin{align*}
    |(fg)(x)-(L_fL_g)|&\leq |g(x)||f(x)-L_f|+|L_f||g(x)-L_g|\\
    &<e/2+e/2=e
\end{align*}

as desired.

\subsubsection*{Reciprocal}

Let $\lim_{x\to a}f(x)=L$. We prove $\lim_{x\to a}\left(\frac{1}{f}\right)(x)=1/L$ when $L\neq 0$.

\vs

First we show $\frac{1}{f}$ is defined near $a$. By half-value
neighborhood lemma (see \ref{subsubsec:half-value-lemma}) there exists
$\delta_{1}$ such that $0<|x-a|<\delta_{1}$ implies $|f(x)|\geq |L|/2$ where
$L\neq0$. Therefore $f(x)\neq 0$ near $a$, and thus $\frac{1}{f}$ near
$a$ is defined.

\vs


Now all we must do is find a delta such that
$\left|\frac{1}{f}(x)-\frac{1}{L}\right|<\epsilon$. Let's make the equation
more convenient:

\begin{align*}
  \left|\frac{1}{f}(x)-\frac{1}{L}\right|&=\left|\frac{1}{f(x)}-\frac{1}{L}\right|\\
                                         &=\left|\frac{L-f(x)}{Lf(x)}\right|\\
                                         &=\frac{|f(x)-L|}{|L||f(x)|}\\
                                         &=\frac{|f(x)-L|}{|L|}\cdot\frac{1}{|f(x)|}
\end{align*}

Above we showed there exists $\delta_{1}$ such that
$0<|x-a|<\delta_{1}$ implies $|f(x)|\geq |L|/2$. Raising both sides to
$-1$ we get $|\frac{1}{f(x)}|\leq \frac{2}{|L|}$. Continuing the chain of
reasoning above we get

\begin{align*}
  \frac{|f(x)-L|}{|L|}\cdot\frac{1}{|f(x)|}&\leq\frac{|f(x)-L|}{|L|}\cdot\frac{2}{|L|}\\
                                       &=\frac{2}{|L|^2}|f(x)-L|
\end{align*}

(if you're confused about why this inequality works, left-multiply both sides of
$|\frac{1}{f(x)}|\leq \frac{2}{|L|}$ by $\frac{|f(x)-L|}{|L|}$.) Thus we
must find $\delta_2$ such that

\[\frac{2}{|L|^2}|f(x)-L|<\epsilon\]

That is easy. Since $\lim_{x\to a}f(x)=L$ we can make $|f(x)-L|$ as
small as we like. Dividing both sides by $\frac{2}{|L|^2}$, we must
make $|f(x)-L|<\frac{|L|^2\epsilon}{2}$. Thus we must fix
$\delta=\min(\delta_1, \delta_2)$. QED.

\subsection{Low-level proofs}

While high level theorems allow us to easily compute complicated
limits, it's instructive to compute a few limits for complicated
functions straight from the definition. We do that here.

\subsubsection*{Aside: inequalities}

We will often need to make an inequality of the following form work out:

\[|n||m|<\epsilon\]

Here $\epsilon$ is given to us, we have complete control over the upper bound
of $|n|$, and $|m|$ can take on values outside our direct control.
Obviously we can't make the inequality work without knowing
\textit{something} about $|m|$, so we'll try to find a bound for it in
terms of other fixed values, or values we control.

\vs

For example, suppose $\lim_{x\to a}f(x)=L$ and we've discovered that
$|m|<3|a|+4$. Given that we control $|n|$, how do we bound it in terms
of $\epsilon$ and $|a|$ in such a way that the inequality $|n||m|<\epsilon$ holds?

\vs

Since we control $|n|$ and $(3|a|+4)$ is fixed, we can find $|n|$
small enough so that $|n|(3|a|+4)<\epsilon$ holds. Then certainly any
inequality whose left side is smaller, e.g. $|n|(3|a|+3)<\epsilon$, will also
hold. And since $|m|$ is always smaller than $3|a|+4$, it follows
$|n||m|<\epsilon$ will hold as well.

\vs

All we have left to do is find a bound for $|n|$ such that
$|n|(3|a|+4)<\epsilon$ holds, which is of course easy:

\[|n|<\frac{\epsilon}{3|a|+4}\]

Having bound $|n|$ in this way, we can verify that
$|n|(3|a|+4)<\epsilon$ holds by multiplying both sides of the above
inequality by $3|a|+4$.

\subsubsection*{Limits of quadratic functions}

We will prove directly from the limits definition that
$\lim_{x\to a}x^2=a^2$. Let $\epsilon>0$ be given. We must show there exists
$\delta$ such that $|x^2-a^2|<\epsilon$ for all $x$ in $0<|x-a|<\delta$.

\vs

Observe that
\[|x^2-a^2|=|(x-a)(x+a)|=|x-a||x+a|\]

Thus we must pick $\delta$ such that $|x-a||x+a|<\epsilon$. Since
$0<|x-a|<\delta$, picking $\delta$ conveniently happens to bound
$|x-a|$, letting us make it as small as we want. But to know how
small, we need to find an upper bound on $|x+a|$. We can do it as
follows.

\vs

Pick an arbitrary $\delta=1$ (we may pick any arbitrary delta, e.g. $1/10$,
$10$, etc.) Then since $|x-a|<\delta$:
\begin{align*}
    &|x-a|<1\\
    &\implies -1<x-a<1\\
    &\implies 2a-1<x+a<2a+1&&\text{add $2a$ to both sides}
\end{align*}

We now have a bound on $x+a$, but we need one on $|x+a|$. It's easy to
see $|x+a|<\max(|2a-1|, |2a+1|)$. By triangle inequality
($|a+b|\leq|a|+|b|$):
\begin{align*}
    &|2a-1|\leq|2a|+|-1|=|2a|+1\\
    &|2a+1|\leq|2a|+|1|=|2a|+1
\end{align*}

Thus $|x+a|<|2a|+1$, provided $|x-a|<1$. Coming back to our original
goal, $|x-a||x+a|<\epsilon$ when

\begin{itemize}
    \item $|x-a|<1$ and
    \item $|x-a|<\frac{\epsilon}{|2a|+1}$
\end{itemize}

Putting these together, $\delta=\min(1, \frac{\epsilon}{|2a|+1})$.

\subsubsection*{Limits of fractions}

We will prove directly from the limits definition that
$\lim_{x\to 2}\frac{3}{x}=\frac{3}{2}$. Let $\epsilon>0$ be given. We must show
there exists $\delta>0$ such that $|\frac{3}{x}-\frac{3}{2}|<\epsilon$ for all
$x$ in $0<|x-2|<\delta$.

\vs

Let's manipulate $|\frac{3}{x}-\frac{3}{2}|$ to make it more convenient:
\[\left|\frac{3}{x}-\frac{3}{2}\right|=\left|\frac{6-3x}{2x}\right|=\frac{3}{2}\frac{|x-2|}{|x|}\]

Thus we need to find $\delta$ such that

\begin{align*}
&\frac{3}{2}\frac{|x-2|}{|x|}<\epsilon\\
&\implies \frac{|x-2|}{|x|}<\frac{2\epsilon}{3}\\
\end{align*}

Conveniently $0<|x-2|<\delta$ bounds $|x-2|$. But now we need to find a
bound for $|x|$. It would be extra convenient if we could show
$|x|>1$. Then we could set $\delta=\frac{2\epsilon}{3}$ (and thus bound
$|x-2|<\frac{2\epsilon}{3}$). A denominator greater than $1$ would only make
the fraction smaller than $\frac{2\epsilon}{3}$, ensuring
$\frac{|x-2|}{|x|}<\frac{2\epsilon}{3}$ holds.

\vs

We will do exactly that. Pick an arbitrary $\delta=1$ (we may pick any
arbitrary delta, e.g. $1/10$, $10$, etc.) Then since $|x-2|<\delta$
\begin{align*}
    &|x-2|<1\\
    &\implies -1<x-2<1\\
    &\implies 1<x<3\\
    &\implies 1<|x|<3
\end{align*}

Yes!! Luckily $\delta=1$ implies $|x|>1$! Thus, provided that
$|x-2|<1$ and $|x-2|<\frac{2\epsilon}{3}$, the inequality
$|\frac{3}{x}-\frac{3}{2}|<\epsilon$ holds. Putting the two constraints
together, we get $\delta=\min(1, \frac{2\epsilon}{3})$.

%%% Local Variables:
%%% TeX-master: "notes"
%%% End:
